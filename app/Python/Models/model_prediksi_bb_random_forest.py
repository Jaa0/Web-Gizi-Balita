# -*- coding: utf-8 -*-
"""Model Prediksi BB - Random Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jd71VpKuH8y7iP9vLEvlNDZo98oTvxyM
"""

# Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.model_selection import cross_val_score, RandomizedSearchCV
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler
import joblib
from imblearn.over_sampling import SMOTE

# Importing Dataset
df = pd.read_excel('EN071R_REGISTER POLI IMUN SDIDTK JAN - 18 SEPTEMBER .xls')

"""#Data Understanding and Cleaning"""

df.head()

# Drop unnecessary column
df = df[['Umur', 'Jenis Kelamin', 'BB', 'INDEX BB/U']]
df

df.info()

df.describe()

# Handling null values
df.isna().sum()

df = df.dropna()
df = df.reset_index(drop=True)
df.info()

plt.figure(figsize=(20, 10))
sns.countplot(x='INDEX BB/U', data=df)
plt.title('Count of Each Classes')
plt.xlabel('INDEX BB/U')
plt.ylabel('Count')
plt.show

df.rename(columns={'Umur': 'Age in Month', 'BB': 'Weight', 'Jenis Kelamin': 'Gender'}, inplace=True)
df

# Converting Age values into month format
def convert_to_months(Age):
    # Separate the string
    parts = Age.split()
    year = int(parts[0])
    month = int(parts[2])
    # Convert and add months
    age_in_month = (year * 12) + month
    return age_in_month

df['Age in Month'] = df['Age in Month'].apply(convert_to_months)
df

# Convert Age in Month to integer
df['Age in Month'] = df['Age in Month'].astype(int)
df.info()

# Remove rows with Age in Month above 60
df = df[df['Age in Month'] <= 60]

# Reset index after filtering
df = df.reset_index(drop=True)

print(df['INDEX BB/U'].value_counts())

"""# Data Preprocessing"""

# Encode categorical column
df['Gender'] = df['Gender'].map({'PRIA':0, 'WANITA':1})
df['INDEX BB/U'] = df['INDEX BB/U'].map({'BERAT BADAN SANGAT KURANG':0, 'BERAT BADAN KURANG':1, 'BERAT BADAN NORMAL':2,
                                           'RISIKO BERAT BADAN LEBIH':3})
print(df['Gender'].unique())
print(df['INDEX BB/U'].unique())

# Split training and testing data
X = df.drop(["INDEX BB/U"], axis=1)
y = df["INDEX BB/U"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

# kfold
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Normalize numerical features
numerical_features = ['Age in Month', 'Weight']
scaler = StandardScaler()

# Fit the scaler on the training data and transform it
X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])

# Transform the test data using the same scaler
X_test[numerical_features] = scaler.transform(X_test[numerical_features])
X_train[numerical_features].head()

"""# Model Development"""

# initialize Random Classifier
rf = RandomForestClassifier()

# define the parameter grid
param_dist = {
    'n_estimators': [100, 200, 400],
    'max_features': ['sqrt', 'log2', None],
    'min_samples_leaf': [2, 4, 6],
    'max_depth': [None, 10, 20],
    'criterion': ['gini', 'entropy'],
    'random_state': [42]
}

# Specify multiple scoring metrics
scoring = {
    'accuracy': make_scorer(accuracy_score),
    'precision': make_scorer(precision_score, average='weighted'),
    'recall': make_scorer(recall_score, average='weighted'),
    'f1': make_scorer(f1_score, average='weighted')
}

random_search = RandomizedSearchCV(estimator=rf,
                                   param_distributions=param_dist,
                                   n_iter=50,  # Number of combinations to sample
                                   scoring=scoring,
                                   refit='f1',
                                   cv=kfold,
                                   n_jobs=-1,
                                   verbose=1,
                                   random_state=42)  # For reproducibility

# Fit the model
random_search.fit(X_train, y_train)

# Retrieve the best model
best_rf_model_bb = random_search.best_estimator_

# Export the best model using joblib
joblib.dump(best_rf_model_bb, 'best_rf_model_bb.joblib')

# Evaluate the model on the test data
y_pred = best_rf_model_bb.predict(X_test)
y_prob = best_rf_model_bb.predict_proba(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['BERAT BADAN SANGAT KURANG', 'BERAT BADAN KURANG',
                                                                   'BERAT BADAN NORMAL', 'RISIKO BERAT BADAN LEBIH'])
fig, ax = plt.subplots(figsize=(20, 10))
disp.plot(cmap=plt.cm.Blues, ax=ax)
plt.xticks(rotation=5)
plt.title("Confusion Matrix")
plt.show()

# Classification evaluation scores (Accuracy, Precision, Recall, F1)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

from sklearn.preprocessing import label_binarize

n_classes = len(np.unique(y_test))

# Binarize the labels for multiclass
y_test_binarized = label_binarize(y_test, classes=np.arange(n_classes))

# Initialize dictionaries for FPR, TPR, and AUC
fpr = dict()
tpr = dict()
roc_auc = dict()

# Compute ROC curve and ROC AUC for each class
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc[i] = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])

# Compute micro-average ROC curve and ROC AUC
fpr_micro, tpr_micro, _ = roc_curve(y_test_binarized.ravel(), y_prob.ravel())
roc_auc_micro = roc_auc_score(y_test_binarized, y_prob, average="micro")

# Compute macro-average ROC AUC
roc_auc_macro = roc_auc_score(y_test_binarized, y_prob, average="macro")

# Plot ROC curves for each class
plt.figure()
colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))

# Plot micro-average ROC curve
plt.plot(fpr_micro, tpr_micro, color='deeppink', linestyle='--', lw=2,
         label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc_micro))

# Plot random guessing line
plt.plot([0, 1], [0, 1], 'k--', lw=2)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curves for Multiclass')
plt.legend(loc="lower right")
plt.show()

# Print micro-average and macro-average ROC AUC
print("Micro-average ROC AUC (area = {:.2f})".format(roc_auc_micro))
print("Macro-average ROC AUC (area = {:.2f})".format(roc_auc_macro))

"""#SMOTE

## Data Preprocessing
"""

# Apply SMOTE only to the training data
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Check the class distribution after applying SMOTE
print("Before SMOTE:")
print(y_train.value_counts())
print("\nAfter SMOTE:")
print(pd.Series(y_train_balanced).value_counts())

# Normalize numerical features
numerical_features = ['Age in Month', 'Weight']
scaler = StandardScaler()

# Fit the scaler on the training data and transform it
X_train_balanced[numerical_features] = scaler.fit_transform(X_train_balanced[numerical_features])

# Transform the test data using the same scaler
X_test[numerical_features] = scaler.transform(X_test[numerical_features])
X_train_balanced[numerical_features].head()

"""## Model Development"""

# initialize Random Classifier
rf = RandomForestClassifier()

# define the parameter grid
param_dist = {
    'n_estimators': [100, 200, 400],
    'max_features': ['sqrt', 'log2', None],
    'min_samples_leaf': [2, 4, 6],
    'max_depth': [None, 10, 20],
    'criterion': ['gini', 'entropy'],
    'random_state': [42]
}

# Specify multiple scoring metrics
scoring = {
    'accuracy': make_scorer(accuracy_score),
    'precision': make_scorer(precision_score, average='weighted'),
    'recall': make_scorer(recall_score, average='weighted'),
    'f1': make_scorer(f1_score, average='weighted')
}

random_search = RandomizedSearchCV(estimator=rf,
                                   param_distributions=param_dist,
                                   n_iter=50,  # Number of combinations to sample
                                   scoring=scoring,
                                   refit='f1',
                                   cv=kfold,
                                   n_jobs=-1,
                                   verbose=1,
                                   random_state=42)  # For reproducibility

# Fit the model
random_search.fit(X_train_balanced, y_train_balanced)

# Retrieve the best model
best_rf_model_smote_bb = random_search.best_estimator_

# Export the best model using joblib
joblib.dump(best_rf_model_smote_bb, 'best_rf_model_smote_bb.joblib')

# Evaluate the model on the test data
y_pred = best_rf_model_smote_bb.predict(X_test)
y_prob = best_rf_model_smote_bb.predict_proba(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['BERAT BADAN SANGAT KURANG', 'BERAT BADAN KURANG',
                                                                   'BERAT BADAN NORMAL', 'RISIKO BERAT BADAN LEBIH'])
fig, ax = plt.subplots(figsize=(20, 10))
disp.plot(cmap=plt.cm.Blues, ax=ax)
plt.xticks(rotation=5)
plt.title("Confusion Matrix")
plt.show()

# Classification evaluation scores (Accuracy, Precision, Recall, F1)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

n_classes = len(np.unique(y_test))

# Binarize the labels for multiclass
y_test_binarized = label_binarize(y_test, classes=np.arange(n_classes))

# Initialize dictionaries for FPR, TPR, and AUC
fpr = dict()
tpr = dict()
roc_auc = dict()

# Compute ROC curve and ROC AUC for each class
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    roc_auc[i] = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])

# Compute micro-average ROC curve and ROC AUC
fpr_micro, tpr_micro, _ = roc_curve(y_test_binarized.ravel(), y_prob.ravel())
roc_auc_micro = roc_auc_score(y_test_binarized, y_prob, average="micro")

# Compute macro-average ROC AUC
roc_auc_macro = roc_auc_score(y_test_binarized, y_prob, average="macro")

# Plot ROC curves for each class
plt.figure()
colors = ['aqua', 'darkorange', 'cornflowerblue', 'green']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))

# Plot micro-average ROC curve
plt.plot(fpr_micro, tpr_micro, color='deeppink', linestyle='--', lw=2,
         label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc_micro))

# Plot random guessing line
plt.plot([0, 1], [0, 1], 'k--', lw=2)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curves for Multiclass')
plt.legend(loc="lower right")
plt.show()

# Print micro-average and macro-average ROC AUC
print("Micro-average ROC AUC (area = {:.2f})".format(roc_auc_micro))
print("Macro-average ROC AUC (area = {:.2f})".format(roc_auc_macro))